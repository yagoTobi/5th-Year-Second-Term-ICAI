{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "S03GRJeEvef8"
   },
   "outputs": [],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yd_g69rzvef-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import norm\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sda6v4Kavef-"
   },
   "outputs": [],
   "source": [
    "# run params\n",
    "section = \"vae\"\n",
    "run_id = \"0001\"\n",
    "data_name = \"faces\"\n",
    "RUN_FOLDER = \"run/{}/\".format(section)\n",
    "RUN_FOLDER += \"_\".join([run_id, data_name])\n",
    "\n",
    "\n",
    "DATA_FOLDER = \"/kaggle/input/celeba-dataset\"\n",
    "IMAGE_FOLDER = \"/kaggle/input/img_align_celeba\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xuYcxn2tvef_"
   },
   "outputs": [],
   "source": [
    "att = pd.read_csv(os.path.join(DATA_FOLDER, \"list_attr_celeba.csv\"))\n",
    "\n",
    "# imageLoader = ImageDataGenerator(IMAGE_FOLDER, INPUT_DIM[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KNOWNAUhvef_"
   },
   "source": [
    "# Parámetros del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "azQQN6-VvegA"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = (64, 64, 3)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "filenames = np.array(\n",
    "    glob(\"../input/celeba-dataset/img_align_celeba/img_align_celeba/*.jpg\")\n",
    ")\n",
    "\n",
    "NUM_IMAGES = len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uYjH51BNvegA"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 50\n",
    "ENCODER_CONV_FILTERS = [32, 64, 128, 256]\n",
    "DECODER_CONV_FILTERS = [256, 128, 64, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxLXi36gvegB"
   },
   "source": [
    "# Generador para entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0BFD742cvegB"
   },
   "outputs": [],
   "source": [
    "data_gen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "data_flow = data_gen.flow_from_directory(\n",
    "    DATA_FOLDER,\n",
    "    target_size=INPUT_DIM[:2],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    class_mode=None,\n",
    "    subset=\"training\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P0ijOnnmvegB"
   },
   "outputs": [],
   "source": [
    "plt.imshow(data_flow.next()[0, :, :, :]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KSK5ft8OvegB"
   },
   "source": [
    "# Generación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J2W_gu54vegB"
   },
   "outputs": [],
   "source": [
    "class Sampling(tf.keras.layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6ec67kovegB"
   },
   "outputs": [],
   "source": [
    "# Encoder\n",
    "\n",
    "\n",
    "def create_encoder():\n",
    "\n",
    "    encoder_input = keras.layers.Input(shape=INPUT_DIM, name=\"encoder_input\")\n",
    "\n",
    "    x = encoder_input\n",
    "\n",
    "    for i in range(len(ENCODER_CONV_FILTERS)):\n",
    "        conv_layer = tf.keras.layers.Conv2D(\n",
    "            filters=ENCODER_CONV_FILTERS[i],\n",
    "            kernel_size=3,\n",
    "            strides=2,\n",
    "            padding=\"same\",\n",
    "            name=\"encoder_conv_\" + str(i),\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "\n",
    "        x = conv_layer(x)\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "        # x = keras.layers.Dropout(rate = 0.25)(x)\n",
    "\n",
    "    shape_before_flattening = K.int_shape(x)[1:]\n",
    "\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    mu = keras.layers.Dense(EMBEDDING_DIM, name=\"mu\")(x)\n",
    "    log_var = keras.layers.Dense(EMBEDDING_DIM, name=\"log_var\")(x)\n",
    "\n",
    "    z = Sampling(name=\"encoder_output\")([mu, log_var])\n",
    "\n",
    "    encoder = keras.models.Model(encoder_input, [mu, log_var, z], name=\"encoder\")\n",
    "    return encoder, shape_before_flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_wqi7S4bvegB"
   },
   "outputs": [],
   "source": [
    "# Decoder\n",
    "def create_decoder(shape_before_flattening):\n",
    "    decoder_input = keras.layers.Input(shape=(EMBEDDING_DIM,), name=\"decoder_input\")\n",
    "\n",
    "    x = keras.layers.Dense(np.prod(shape_before_flattening))(decoder_input)\n",
    "    x = keras.layers.Reshape(shape_before_flattening)(x)\n",
    "\n",
    "    for i in range(len(DECODER_CONV_FILTERS)):\n",
    "        conv_t_layer = keras.layers.Conv2DTranspose(\n",
    "            filters=DECODER_CONV_FILTERS[i],\n",
    "            kernel_size=3,\n",
    "            strides=2,\n",
    "            padding=\"same\",\n",
    "            name=\"decoder_conv_t_\" + str(i),\n",
    "            activation=\"sigmoid\" if i == (len(DECODER_CONV_FILTERS) - 1) else \"relu\",\n",
    "        )\n",
    "\n",
    "        x = conv_t_layer(x)\n",
    "\n",
    "        if i != (len(DECODER_CONV_FILTERS) - 1):\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "            # x = keras.layers.Dropout(rate = 0.25)(x)\n",
    "\n",
    "    decoder = keras.models.Model(decoder_input, x, name=\"decoder\")\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v29DdCzUvegC"
   },
   "outputs": [],
   "source": [
    "class VAEModel(keras.models.Model):\n",
    "    def __init__(self, encoder, decoder, r_loss_factor, **kwargs):\n",
    "        super(VAEModel, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.r_loss_factor = r_loss_factor\n",
    "\n",
    "    def compute_losses(self, data):\n",
    "        z_mean, z_log_var, z = self.encoder(data)\n",
    "        reconstruction = self.decoder(z)\n",
    "        reconstruction_loss = tf.reduce_mean(\n",
    "            tf.square(data - reconstruction), axis=[1, 2, 3]\n",
    "        )\n",
    "        kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "        kl_loss = tf.reduce_sum(kl_loss, axis=1)\n",
    "        kl_loss *= -0.5\n",
    "        total_loss = (\n",
    "            self.r_loss_factor * reconstruction_loss + kl_loss\n",
    "        ) / self.r_loss_factor\n",
    "        return reconstruction_loss, kl_loss, total_loss\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            reconstruction_loss, kl_loss, total_loss = self.compute_losses(data)\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "        }\n",
    "\n",
    "    def call(self, inputs):\n",
    "        latent = self.encoder(inputs)[2]\n",
    "        return self.decoder(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T10:10:30.361069Z",
     "iopub.status.busy": "2023-03-05T10:10:30.360795Z",
     "iopub.status.idle": "2023-03-05T10:10:30.529692Z",
     "shell.execute_reply": "2023-03-05T10:10:30.528958Z",
     "shell.execute_reply.started": "2023-03-05T10:10:30.361039Z"
    },
    "id": "V8MEyNjivegC"
   },
   "outputs": [],
   "source": [
    "encoder, shape_before_flattening = create_encoder()\n",
    "decoder = create_decoder(shape_before_flattening)\n",
    "vae = VAEModel(encoder, decoder, 10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T10:10:30.686963Z",
     "iopub.status.busy": "2023-03-05T10:10:30.686712Z",
     "iopub.status.idle": "2023-03-05T10:10:30.699763Z",
     "shell.execute_reply": "2023-03-05T10:10:30.698746Z",
     "shell.execute_reply.started": "2023-03-05T10:10:30.686935Z"
    },
    "id": "T_Ul1jHPvegC",
    "outputId": "28742266-a445-47bf-bef3-67b3669df73c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_0 (Conv2D)         (None, 32, 32, 32)   896         encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 32)   128         encoder_conv_0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_1 (Conv2D)         (None, 16, 16, 64)   18496       batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 64)   256         encoder_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_2 (Conv2D)         (None, 8, 8, 128)    73856       batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 8, 128)    512         encoder_conv_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_3 (Conv2D)         (None, 4, 4, 256)    295168      batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 4, 4, 256)    1024        encoder_conv_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 4096)         0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 200)          819400      flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_var (Dense)                 (None, 200)          819400      flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_output (Sampling)       (None, 200)          0           mu[0][0]                         \n",
      "                                                                 log_var[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,029,136\n",
      "Trainable params: 2,028,176\n",
      "Non-trainable params: 960\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T10:10:32.776676Z",
     "iopub.status.busy": "2023-03-05T10:10:32.775011Z",
     "iopub.status.idle": "2023-03-05T10:10:32.785964Z",
     "shell.execute_reply": "2023-03-05T10:10:32.785167Z",
     "shell.execute_reply.started": "2023-03-05T10:10:32.776632Z"
    },
    "id": "erkRFdbMvegC"
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "vae.compile(optimizer=optimizer)\n",
    "# vae.compile(\"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ly7iCnfFvegC"
   },
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T10:10:43.020858Z",
     "iopub.status.busy": "2023-03-05T10:10:43.020151Z",
     "iopub.status.idle": "2023-03-05T10:10:43.027645Z",
     "shell.execute_reply": "2023-03-05T10:10:43.026903Z",
     "shell.execute_reply.started": "2023-03-05T10:10:43.020821Z"
    },
    "id": "JFBPaHuvvegC"
   },
   "outputs": [],
   "source": [
    "def generate_data(flow):\n",
    "    while True:\n",
    "        flow.reset()\n",
    "        while True:\n",
    "\n",
    "            X = flow.next()\n",
    "            if len(X) == BATCH_SIZE:\n",
    "                yield X\n",
    "            else:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T10:10:49.437941Z",
     "iopub.status.busy": "2023-03-05T10:10:49.437676Z",
     "iopub.status.idle": "2023-03-05T10:10:49.442269Z",
     "shell.execute_reply": "2023-03-05T10:10:49.441545Z",
     "shell.execute_reply.started": "2023-03-05T10:10:49.437912Z"
    },
    "id": "J1fPift0vegC"
   },
   "outputs": [],
   "source": [
    "FILEPATH = \"model_checkpoint\"\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    FILEPATH,\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=0,\n",
    "    save_best_only=False,\n",
    "    save_weights_only=False,\n",
    "    mode=\"auto\",\n",
    "    save_freq=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T10:10:51.793851Z",
     "iopub.status.busy": "2023-03-05T10:10:51.793380Z",
     "iopub.status.idle": "2023-03-05T10:10:51.800011Z",
     "shell.execute_reply": "2023-03-05T10:10:51.799252Z",
     "shell.execute_reply.started": "2023-03-05T10:10:51.793820Z"
    },
    "id": "hWPkQm8LvegD"
   },
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    return lr * tf.math.exp(-0.1)\n",
    "\n",
    "\n",
    "scheduler_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T10:10:54.006808Z",
     "iopub.status.busy": "2023-03-05T10:10:54.006236Z",
     "iopub.status.idle": "2023-03-05T14:35:17.322169Z",
     "shell.execute_reply": "2023-03-05T14:35:17.321399Z",
     "shell.execute_reply.started": "2023-03-05T10:10:54.006770Z"
    },
    "id": "JrK7S_8KvegD",
    "outputId": "b40b8fa8-e24d-4186-f58b-a7d874bff5ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6332/6332 [==============================] - 964s 152ms/step - loss: 0.0287 - reconstruction_loss: 0.0237 - kl_loss: 50.1351\n",
      "Epoch 2/50\n",
      "6332/6332 [==============================] - 318s 50ms/step - loss: 0.0217 - reconstruction_loss: 0.0163 - kl_loss: 54.4973\n",
      "Epoch 3/50\n",
      "6332/6332 [==============================] - 301s 48ms/step - loss: 0.0209 - reconstruction_loss: 0.0153 - kl_loss: 56.2760\n",
      "Epoch 4/50\n",
      "6332/6332 [==============================] - 299s 47ms/step - loss: 0.0205 - reconstruction_loss: 0.0148 - kl_loss: 57.0564\n",
      "Epoch 5/50\n",
      "6332/6332 [==============================] - 299s 47ms/step - loss: 0.0203 - reconstruction_loss: 0.0145 - kl_loss: 57.5783\n",
      "Epoch 6/50\n",
      "6332/6332 [==============================] - 295s 47ms/step - loss: 0.0201 - reconstruction_loss: 0.0143 - kl_loss: 57.9293\n",
      "Epoch 7/50\n",
      "6332/6332 [==============================] - 298s 47ms/step - loss: 0.0200 - reconstruction_loss: 0.0142 - kl_loss: 58.1198\n",
      "Epoch 8/50\n",
      "6332/6332 [==============================] - 290s 46ms/step - loss: 0.0199 - reconstruction_loss: 0.0141 - kl_loss: 58.2801\n",
      "Epoch 9/50\n",
      "6332/6332 [==============================] - 296s 47ms/step - loss: 0.0198 - reconstruction_loss: 0.0140 - kl_loss: 58.4003\n",
      "Epoch 10/50\n",
      "6332/6332 [==============================] - 291s 46ms/step - loss: 0.0198 - reconstruction_loss: 0.0139 - kl_loss: 58.5005\n",
      "Epoch 11/50\n",
      "6332/6332 [==============================] - 290s 46ms/step - loss: 0.0197 - reconstruction_loss: 0.0138 - kl_loss: 58.5967\n",
      "Epoch 12/50\n",
      "6332/6332 [==============================] - 290s 46ms/step - loss: 0.0196 - reconstruction_loss: 0.0138 - kl_loss: 58.6594\n",
      "Epoch 13/50\n",
      "6332/6332 [==============================] - 288s 46ms/step - loss: 0.0196 - reconstruction_loss: 0.0137 - kl_loss: 58.7224\n",
      "Epoch 14/50\n",
      "6332/6332 [==============================] - 289s 46ms/step - loss: 0.0196 - reconstruction_loss: 0.0137 - kl_loss: 58.8045\n",
      "Epoch 15/50\n",
      "6332/6332 [==============================] - 291s 46ms/step - loss: 0.0195 - reconstruction_loss: 0.0136 - kl_loss: 58.9457\n",
      "Epoch 16/50\n",
      "6332/6332 [==============================] - 292s 46ms/step - loss: 0.0195 - reconstruction_loss: 0.0136 - kl_loss: 59.0449\n",
      "Epoch 17/50\n",
      "6332/6332 [==============================] - 289s 46ms/step - loss: 0.0194 - reconstruction_loss: 0.0135 - kl_loss: 59.1307\n",
      "Epoch 18/50\n",
      "6332/6332 [==============================] - 296s 47ms/step - loss: 0.0194 - reconstruction_loss: 0.0135 - kl_loss: 59.2242\n",
      "Epoch 19/50\n",
      "6332/6332 [==============================] - 290s 46ms/step - loss: 0.0194 - reconstruction_loss: 0.0135 - kl_loss: 59.2482\n",
      "Epoch 20/50\n",
      "6332/6332 [==============================] - 291s 46ms/step - loss: 0.0194 - reconstruction_loss: 0.0134 - kl_loss: 59.3189\n",
      "Epoch 21/50\n",
      "6332/6332 [==============================] - 295s 47ms/step - loss: 0.0194 - reconstruction_loss: 0.0134 - kl_loss: 59.3512\n",
      "Epoch 22/50\n",
      "6332/6332 [==============================] - 295s 47ms/step - loss: 0.0193 - reconstruction_loss: 0.0134 - kl_loss: 59.3789\n",
      "Epoch 23/50\n",
      "6332/6332 [==============================] - 295s 47ms/step - loss: 0.0193 - reconstruction_loss: 0.0134 - kl_loss: 59.3923\n",
      "Epoch 24/50\n",
      "6332/6332 [==============================] - 303s 48ms/step - loss: 0.0193 - reconstruction_loss: 0.0134 - kl_loss: 59.4214\n",
      "Epoch 25/50\n",
      "6332/6332 [==============================] - 303s 48ms/step - loss: 0.0193 - reconstruction_loss: 0.0134 - kl_loss: 59.4488\n",
      "Epoch 26/50\n",
      "6332/6332 [==============================] - 307s 48ms/step - loss: 0.0193 - reconstruction_loss: 0.0133 - kl_loss: 59.4645\n",
      "Epoch 27/50\n",
      "6332/6332 [==============================] - 308s 49ms/step - loss: 0.0193 - reconstruction_loss: 0.0133 - kl_loss: 59.4777\n",
      "Epoch 28/50\n",
      "6332/6332 [==============================] - 305s 48ms/step - loss: 0.0193 - reconstruction_loss: 0.0133 - kl_loss: 59.5101\n",
      "Epoch 29/50\n",
      "6332/6332 [==============================] - 309s 49ms/step - loss: 0.0193 - reconstruction_loss: 0.0133 - kl_loss: 59.5261\n",
      "Epoch 30/50\n",
      "6332/6332 [==============================] - 304s 48ms/step - loss: 0.0193 - reconstruction_loss: 0.0133 - kl_loss: 59.5483\n",
      "Epoch 31/50\n",
      "6332/6332 [==============================] - 309s 49ms/step - loss: 0.0193 - reconstruction_loss: 0.0133 - kl_loss: 59.5321\n",
      "Epoch 32/50\n",
      "6332/6332 [==============================] - 298s 47ms/step - loss: 0.0192 - reconstruction_loss: 0.0133 - kl_loss: 59.5568\n",
      "Epoch 33/50\n",
      "6332/6332 [==============================] - 305s 48ms/step - loss: 0.0192 - reconstruction_loss: 0.0133 - kl_loss: 59.5343\n",
      "Epoch 34/50\n",
      "6332/6332 [==============================] - 302s 48ms/step - loss: 0.0192 - reconstruction_loss: 0.0133 - kl_loss: 59.5715\n",
      "Epoch 35/50\n",
      "6332/6332 [==============================] - 305s 48ms/step - loss: 0.0192 - reconstruction_loss: 0.0133 - kl_loss: 59.5545\n",
      "Epoch 36/50\n",
      "6332/6332 [==============================] - 310s 49ms/step - loss: 0.0192 - reconstruction_loss: 0.0133 - kl_loss: 59.5714\n",
      "Epoch 37/50\n",
      "6332/6332 [==============================] - 310s 49ms/step - loss: 0.0192 - reconstruction_loss: 0.0133 - kl_loss: 59.6078\n",
      "Epoch 38/50\n",
      "6332/6332 [==============================] - 304s 48ms/step - loss: 0.0192 - reconstruction_loss: 0.0133 - kl_loss: 59.5853\n",
      "Epoch 39/50\n",
      "6332/6332 [==============================] - 306s 48ms/step - loss: 0.0192 - reconstruction_loss: 0.0133 - kl_loss: 59.6011\n",
      "Epoch 40/50\n",
      "6332/6332 [==============================] - 314s 50ms/step - loss: 0.0192 - reconstruction_loss: 0.0133 - kl_loss: 59.6162\n",
      "Epoch 41/50\n",
      "6332/6332 [==============================] - 302s 48ms/step - loss: 0.0192 - reconstruction_loss: 0.0133 - kl_loss: 59.6068\n",
      "Epoch 42/50\n",
      "6332/6332 [==============================] - 297s 47ms/step - loss: 0.0192 - reconstruction_loss: 0.0133 - kl_loss: 59.6074\n",
      "Epoch 43/50\n",
      "6332/6332 [==============================] - 294s 47ms/step - loss: 0.0192 - reconstruction_loss: 0.0133 - kl_loss: 59.6063\n",
      "Epoch 44/50\n",
      "6332/6332 [==============================] - 300s 47ms/step - loss: 0.0192 - reconstruction_loss: 0.0133 - kl_loss: 59.6158\n",
      "Epoch 45/50\n",
      "6332/6332 [==============================] - 290s 46ms/step - loss: 0.0192 - reconstruction_loss: 0.0132 - kl_loss: 59.6244\n",
      "Epoch 46/50\n",
      "6332/6332 [==============================] - 294s 46ms/step - loss: 0.0192 - reconstruction_loss: 0.0132 - kl_loss: 59.6098\n",
      "Epoch 47/50\n",
      "6332/6332 [==============================] - 294s 46ms/step - loss: 0.0192 - reconstruction_loss: 0.0132 - kl_loss: 59.6129\n",
      "Epoch 48/50\n",
      "6332/6332 [==============================] - 289s 46ms/step - loss: 0.0192 - reconstruction_loss: 0.0132 - kl_loss: 59.6162\n",
      "Epoch 49/50\n",
      "6332/6332 [==============================] - 290s 46ms/step - loss: 0.0192 - reconstruction_loss: 0.0132 - kl_loss: 59.6237\n"
     ]
    }
   ],
   "source": [
    "data_flow.reset()\n",
    "history = vae.fit(\n",
    "    generate_data(data_flow),\n",
    "    steps_per_epoch=len(data_flow),\n",
    "    epochs=50,\n",
    "    callbacks=[checkpoint_callback, scheduler_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "id": "3PeCEN4xvegD"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "encoder.save(f\"Embedding_{EMBEDDING_DIM}/encoder\")\n",
    "decoder.save(f\"Embedding_{EMBEDDING_DIM}/decoder\")\n",
    "shutil.make_archive(f\"Embedding_{EMBEDDING_DIM}\", \"zip\", \".\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}