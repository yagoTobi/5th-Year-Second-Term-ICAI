{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  **4. Recommender Systems**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommender systems are systems which recommend items (such as movies, books, ads) to users based on various information, such as their past viewing/purchasing behavior (e.g., which movies they rated high or low, which ads they clicked on), as well as optional “side information” such as demographics about the user, or information about the content of the item (e.g., its title, genre or price). Such systems are widely used by various internet companies, such as Facebook, Amazon, Netflix, Google, etc.  \n",
    "\n",
    "The internet has changed how we consume media, products, and services. With so many options and choices, it becomes overwhelming to select the right one. That’s where Recommender Systems come in. Recommender Systems are intelligent algorithms that analyze user behaviour, preferences, and data to suggest personalized recommendations. These systems are widely used in e-commerce, streaming services, social networks, and other domains.\n",
    "\n",
    "In this chapter, we give a brief introduction to the topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![scheme](https://www.researchgate.net/profile/Mohammad-Zahrawi/publication/354259927/figure/fig1/AS:1073092147294208@1632856513395/The-main-types-of-recommendation-system.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **COLLABORATIVE FILTERING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![advantages](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7uW5hLXztSu_FOmZOWpB6g.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.1 Memory-Based Collaborative Filtering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Memory-based** collaborative filtering algorithms, also referred to as **Neighborhood-based** algorithms, were among the earliest algorithms developed for collaborative filtering. These algorithms are based on the fact that similar users display similar patterns of rating behavior and similar items receive similar ratings. There are two primary types of neighborhood-based algorithms:\n",
    "\n",
    "1. **User-based** collaborative filtering: In this case, the ratings provided by similar users to a target user A are used to make recommendations for A. The predicted ratings of A are computed as the weighted average values of these “peer group” ratings for each item.\n",
    "   \n",
    "2. **Item-based** collaborative filtering: In order to make recommendations for target item B, the first step is to determine a set S of items, which are most similar to item B. Then, in order to predict the rating of any particular user A for item B, the ratings in set S, which are specified by A, are determined. The weighted average of these ratings is used to compute the predicted rating of user A for item B.\n",
    "\n",
    "An important distinction between user-based collaborative filtering and item-based collaborative filtering algorithms is that the ratings in the former case are predicted using the ratings of neighboring users, whereas the ratings in the latter case are predicted using the user’s own ratings on neighboring (i.e., closely related) items. In the former case, neighborhoods are defined by similarities among users (rows of ratings matrix), whereas in the latter case, neighborhoods are defined by similarities among items (columns of ratings matrix). Thus, the two methods share a complementary relationship. Nevertheless, there are considerable differences in the types of recommendations that are achieved using these two methods.\n",
    "For the purpose of subsequent discussion, we assume that the user-item ratings matrix is an incomplete $m × n$ matrix $R = [r_{uj}]$ containing $m$ users and $n$ items. It is assumed that only a small subset of the ratings matrix is specified or observed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like all other collaborative filtering algorithms, neighborhood-based collaborative filtering algorithms can be formulated in one of two ways:\n",
    "\n",
    "1. *Predicting the rating value of a user-item combination*: This is the simplest and most primitive formulation of a recommender system. In this case, the missing rating ruj of the user u for item j is predicted.\n",
    "   \n",
    "2. *Determining the top-k items or top-k users*: In most practical settings, the merchant is not necessarily looking for specific ratings values of user-item combinations. Rather, it is more interesting to learn the top-k most relevant items for a particular user, or the top-k most relevant users for a particular item. The problem of determining the top-k items is more common than that of finding the top-k users. This is because the former formulation is used to present lists of recommended items to users in Web- centric scenarios. In traditional recommender algorithms, the “top-k problem” almost always refers to the process of finding the top-k items, rather than the top-k users. However, the latter formulation is also useful to the merchant because it can be used to determine the best users to target with marketing efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Key propierties of Rating Matrices**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed earlier, we assume that the ratings matrix is denoted by $R$, and it is an m × n matrix containing m users and n items. Therefore, the rating of user u for item j is denoted by ruj. Only a small subset of the entries in the ratings matrix are typically specified. The specified entries of the matrix are referred to as the training data, whereas the unspecified entries of the matrix are referred to as the test data. In that case, all the unspecified entries belong to a special column, which is known as the class variable or dependent variable. Therefore, the recommendation problem can be viewed as a generalization of the problem of classification and regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ratings can be defined in a variety of ways, depending on the application at hand:\n",
    "1. Continuous ratings. \n",
    "2. Interval-based ratings.\n",
    "3. Ordinal ratings.\n",
    "4. Binary ratings.\n",
    "5. Unary ratings.\n",
    "   \n",
    "\n",
    "It is noteworthy that the indirect derivation of unary ratings from customer actions is also referred to as implicit feedback, because the customer does not explicitly provide feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Long-tail property**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of ratings among items often satisfies a property in real-world settings, which is referred to as the long-tail property. According to this property, only a small fraction of the items are rated frequently. Such items are referred to as popular items. The vast majority of items are rated rarely. This results in a highly skewed distribution of the underlying ratings. An example of a skewed rating distribution is illustrated in Figure 2.1. The X-axis shows the index of the item in order of decreasing frequency, and the Y -axis shows the frequency with which the item was rated. It is evident that most of the items are rated only a small number of times. Such a rating distribution has important implications for the recommendation process:\n",
    "\n",
    "1. In many cases, the high-frequency items tend to be relatively competitive items with little profit for the merchant. On the other hand, the lower frequency items have larger profit margins. In such cases, it may be advantageous to the merchant to recommend lower frequency items. In fact, analysis suggests that many companies, such as Amazon, make most of their profit by selling items in the long tail.\n",
    "   \n",
    "2. Because of the rarity of observed ratings in the long tail it is generally more difficult to provide robust rating predictions in the long tail. In fact, many recommendation algorithms have a tendency to suggest popular items rather than infrequent items. This phenomenon also has a negative impact on diversity, and users may often become bored by receiving the same set of recommendations of popular items.\n",
    "   \n",
    "3. The long tailed distribution implies that the items, which are frequently rated by users, are fewer in number. This fact has important implications for neighborhood- based collaborative filtering algorithms because the neighborhoods are often defined on the basis of these frequently rated items. In many cases, the ratings of these high-frequency items are not representative of the low-frequency items because of the in- herent differences in the rating patterns of the two classes of items. As a result, the prediction process may yield misleading results. As we will discuss in section 7.6 of Chapter 7, this phenomenon can also cause misleading evaluations of recommendation algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#![longtail](https://lh6.googleusercontent.com/#NlrWR-SLfo5K7w2pFzFqcmWVVe0YNQvtbJ_iIkhGhWwDU6nnkpR0Vzh8xjenCCW2i3hg_Y1MPxNVVoc6zIgC1O14pN-CTYlr9amX1TcgmXi59ryLD5_FnKKov72Oa55HfMY-4eNAQlMrQcBaMQIMIGIEEy8Z1DvnUEFqSOy4GJYv12d8tUmH126RUX-wKw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The basic idea in neighborhood-based methods is to use either user-user similarity or item- item similarity to make recommendations from a ratings matrix. The concept of a neigh- borhood implies that we need to determine either similar users or similar items in order to make predictions. In the following, we will discuss how neighborhood-based methods can be used to predict the ratings of specific user-item combinations. There are two basic principles used in neighborhood-based models:\n",
    "- (a) **User-based models**: Similar users have similar ratings on the same item. Therefore, if Alice and Bob have rated movies in a similar way in the past, then one can use Alice’s observed ratings on the movie Terminator to predict Bob’s unobserved ratings on this movie.\n",
    "- (b) **Item-based models**: Similar items are rated in a similar way by the same user. Therefore, Bob’s ratings on similar science fiction movies like Alien and Predator can be used to predict his rating on Terminator.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![useitem](https://www.researchgate.net/publication/355218515/figure/fig2/AS:1079169563787266@1634305482033/The-collaborative-filtering-algorithms-a-user-based-b-item-based.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1.1 User-based models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this approach, user-based neighborhoods are defined in order to identify similar users to the target user for whom the rating predictions are being computed. In order to determine the neighborhood of the target user i, her similarity to all the other users is computed. Therefore, a similarity function needs to be defined between the ratings specified by users. Such a similarity computation is tricky because different users may have different scales of ratings. One user might be biased toward liking most items, whereas another user might be biased toward not liking most of the items. Furthermore, different users may have rated different items. Therefore, mechanisms need to be identified to address these issues.\n",
    "\n",
    "For the $m \\times n$ ratings matrix $R = [r_{uj}]$ with $m$ users and $n$ items, let $I_{u}$ denote the set of item indices for which ratings have been specified by user (row) $u$. For example, if the ratings of the first, third, and fifth items (columns) of user (row) $u$ are specified (observed)and the remaining are missing, then we have $I_{u} = \\{1,3,5\\}$.\n",
    "\n",
    "Therefore, the set of items rated by both users $u$ and $v$ is given by $I_{u} \\cap I_{v} $. For example, if user $v$ has rated the first fouritems,then $I_{v} =\\{1,2,3,4\\}$,and $I_{u}\\cap I_{v} =\\{1,3,5\\}\\cap\\{1,2,3,4\\}=\\{1,3\\}$.\n",
    "\n",
    "It is possible (and quite common) for $I_{u}\\cap I_{v}$ to be an empty set because ratings matrices are generally sparse. The set $I_{u}\\cap I_{v}$ defines the mutually observed ratings, which are used to compute the similarity between the $u$ th and $v$ th users for neighborhood computation.\n",
    "\n",
    "One measure that captures the similarity $Sim(u,v)$ between the rating vectors of two users $u$ and $v$ is the Pearson correlation coefficient. Because $I_{u}\\cap I_{v}$ represents the set of item indices for which both user u and user v have specified ratings, the coefficient is computed only on this set of items. \n",
    "\n",
    "The first step is to compute the **mean rating $\\mu_{u}$** for each user $u$ using her specified ratings:\n",
    "\n",
    "$$ \\mu_{u} = \\frac{\\sum_{k \\in I_{u}} r_{uk}}{|I_{u}|} \\quad \\forall u \\in \\{ 1, \\cdots, m\\}$$\n",
    "\n",
    "Then, the **Pearson correlation coefficient** between the rows (users) u and v is defined as\n",
    "follows:\n",
    "\n",
    "$$Sim(u,v) = Pearson(u,v) = \\frac{\\sum_{k \\in I_{u}\\cap I_{v}}(r_{uk} - \\mu_{u}) \\cdot (r_{vk} - \\mu_{v})}{\\sqrt{\\sum_{k \\in I_{u}\\cap I_{v}}(r_{uk} - \\mu_{u})^{2}} \\cdot \\sqrt{\\sum_{k \\in I_{u}\\cap I_{v}}(r_{vk} - \\mu_{v})^{2}}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strictly speaking, the traditional definition of Pearson(u,v) tells us that the values of $\\mu_{u}$ and $\\mu_{v}$ should be computed only over the items that are rated both by users $u$ and $v$. \n",
    "\n",
    "However, it is quite common (and computationally simpler) to compute each $\\mu_{u}$ just once for each user $u$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine Similarity: \n",
    "\n",
    "\\begin{align*}\n",
    "\\mathrm{Cosine}(u,v) &= \\frac{\\Sigma_{k \\in \\mathcal{I}_u \\cap \\mathcal{I}_v} r_{uk} * r_{vk}}{\\sqrt{\\Sigma_{k \\in \\mathcal{I}_u \\cap \\mathcal{I}_v} r_{uk}^2} * \\sqrt{\\Sigma_{k \\in \\mathcal{I}_u \\cap \\mathcal{I}_v} r_{vk}^2}}\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import isnan\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_1</th>\n",
       "      <th>item_2</th>\n",
       "      <th>item_3</th>\n",
       "      <th>item_4</th>\n",
       "      <th>item_5</th>\n",
       "      <th>item_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user_1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_1  item_2  item_3  item_4  item_5  item_6\n",
       "user_1     7.0     6.0     7.0     4.0     5.0     4.0\n",
       "user_2     6.0     7.0     NaN     4.0     3.0     4.0\n",
       "user_3     NaN     3.0     3.0     1.0     1.0     NaN\n",
       "user_4     1.0     2.0     2.0     3.0     3.0     4.0\n",
       "user_5     1.0     NaN     1.0     2.0     3.0     3.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"user_1\": [7, 6, 7, 4, 5, 4],\n",
    "        \"user_2\": [6, 7, np.nan, 4, 3, 4],\n",
    "        \"user_3\": [np.nan, 3, 3, 1, 1, np.nan],\n",
    "        \"user_4\": [1, 2, 2, 3, 3, 4],\n",
    "        \"user_5\": [1, np.nan, 1, 2, 3, 3],\n",
    "    },\n",
    "    index=[\"item_1\", \"item_2\", \"item_3\", \"item_4\", \"item_5\", \"item_6\"],\n",
    ")\n",
    "\n",
    "df = df.T\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_1</th>\n",
       "      <th>item_2</th>\n",
       "      <th>item_3</th>\n",
       "      <th>item_4</th>\n",
       "      <th>item_5</th>\n",
       "      <th>item_6</th>\n",
       "      <th>Mean Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user_1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_1  item_2  item_3  item_4  item_5  item_6  Mean Rating\n",
       "user_1     7.0     6.0     7.0     4.0     5.0     4.0          5.5\n",
       "user_2     6.0     7.0     NaN     4.0     3.0     4.0          4.8\n",
       "user_3     NaN     3.0     3.0     1.0     1.0     NaN          2.0\n",
       "user_4     1.0     2.0     2.0     3.0     3.0     4.0          2.5\n",
       "user_5     1.0     NaN     1.0     2.0     3.0     3.0          2.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Mean Rating\"] = df.mean(axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_pearson(df, j):\n",
    "    pearson_values = []\n",
    "    for i in np.arange(len(df.values)):\n",
    "        mask = ~isnan(df.values[i]) * ~isnan(df.values[j])\n",
    "        mu_u = df[\"Mean Rating\"].iloc[i]\n",
    "        mu_v = df[\"Mean Rating\"].iloc[j]\n",
    "        ru = df.values[i][mask]\n",
    "        rv = df.values[j][mask]\n",
    "\n",
    "        numerador = np.sum((ru - mu_u) * (rv - mu_v))\n",
    "        denominador = np.sqrt(np.sum((ru - mu_u) ** 2) * np.sum((rv - mu_v) ** 2))\n",
    "\n",
    "        pearson = numerador / denominador\n",
    "        pearson_values.append(pearson)\n",
    "    return pearson_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_1</th>\n",
       "      <th>item_2</th>\n",
       "      <th>item_3</th>\n",
       "      <th>item_4</th>\n",
       "      <th>item_5</th>\n",
       "      <th>item_6</th>\n",
       "      <th>Mean Rating</th>\n",
       "      <th>Pearson (i, 3)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user_1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.894427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.938474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.816497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_1  item_2  item_3  item_4  item_5  item_6  Mean Rating  \\\n",
       "user_1     7.0     6.0     7.0     4.0     5.0     4.0          5.5   \n",
       "user_2     6.0     7.0     NaN     4.0     3.0     4.0          4.8   \n",
       "user_3     NaN     3.0     3.0     1.0     1.0     NaN          2.0   \n",
       "user_4     1.0     2.0     2.0     3.0     3.0     4.0          2.5   \n",
       "user_5     1.0     NaN     1.0     2.0     3.0     3.0          2.0   \n",
       "\n",
       "        Pearson (i, 3)  \n",
       "user_1        0.894427  \n",
       "user_2        0.938474  \n",
       "user_3        1.000000  \n",
       "user_4       -1.000000  \n",
       "user_5       -0.816497  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Pearson (i, 3)\"] = sim_pearson(df, 2)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_cosine(df, i, j):\n",
    "    mask = ~isnan(df.values[i]) * ~isnan(df.values[j])\n",
    "    ru = df.values[i][mask]\n",
    "    rv = df.values[j][mask]\n",
    "    cosine = (np.dot(ru, rv)) / (LA.norm(ru) * LA.norm(rv))\n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_1</th>\n",
       "      <th>item_2</th>\n",
       "      <th>item_3</th>\n",
       "      <th>item_4</th>\n",
       "      <th>item_5</th>\n",
       "      <th>item_6</th>\n",
       "      <th>Mean Rating</th>\n",
       "      <th>Pearson (i, 3)</th>\n",
       "      <th>Cosine (i, 3)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user_1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.894427</td>\n",
       "      <td>0.955867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.938474</td>\n",
       "      <td>0.973637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.763057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>0.647120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_1  item_2  item_3  item_4  item_5  item_6  Mean Rating  \\\n",
       "user_1     7.0     6.0     7.0     4.0     5.0     4.0          5.5   \n",
       "user_2     6.0     7.0     NaN     4.0     3.0     4.0          4.8   \n",
       "user_3     NaN     3.0     3.0     1.0     1.0     NaN          2.0   \n",
       "user_4     1.0     2.0     2.0     3.0     3.0     4.0          2.5   \n",
       "user_5     1.0     NaN     1.0     2.0     3.0     3.0          2.0   \n",
       "\n",
       "        Pearson (i, 3)  Cosine (i, 3)  \n",
       "user_1        0.894427       0.955867  \n",
       "user_2        0.938474       0.973637  \n",
       "user_3        1.000000       1.000000  \n",
       "user_4       -1.000000       0.763057  \n",
       "user_5       -0.816497       0.647120  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Cosine (i, 3)\"] = [sim_cosine(df, i, 2) for i in np.arange(len(df.values))]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Pearson's \n",
    "\n",
    "Pros:\n",
    "- **Context Sensitivity:** Adjusts for users' rating scales, identifying patterns even if users rate differently.\n",
    "- **Normalization:** Accounts for rating biases, useful when users have varying rating scales.\n",
    "\n",
    "Cons:\n",
    "- **Sparse Data Sensitivity:** Less reliable in datasets with few common ratings between users.\n",
    "- **Computationally Intensive:** Requires more calculations, especially in large datasets.\n",
    "\n",
    "#### Cosine \n",
    "\n",
    "Pros:\n",
    "- **Efficiency:** More computationally efficient, particularly with large, sparse datasets.\n",
    "- **Versatility:** Suitable for various data types and effective in high-dimensional spaces.\n",
    "\n",
    "Cons:\n",
    "- **Lack of Normalization:** Does not adjust for differences in users' rating behaviors.\n",
    "- **Insensitive to Rating Scale:** Overlooks variations in user rating patterns.\n",
    "\n",
    "The choice between Pearson's and cosine similarity depends on dataset characteristics and requirements. Pearson's is beneficial for adjusting to users' rating biases, while cosine is preferred for computational efficiency and high-dimensional data applicability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choosing your neighboors**\n",
    "\n",
    "The Pearson coefficient is computed between the target user and all the other users. One way of defining the peer group of the target user would be to use the set of k users with the highest Pearson coefficient with the target. However, since the number of observed ratings in the top-k peer group of a target user may vary significantly with the item at hand, the closest k users are found for the target user separately for each predicted item, such that each of these k users have specified ratings for that item. The weighted average of these ratings can be returned as the predicted rating for that item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main problem with this approach is that different users may provide ratings on different scales. One user might rate all items highly, whereas another user might rate all items negatively. The raw ratings, therefore, need to be mean-centered in row-wise fashion, before determining the (weighted) average rating of the peer group. The **mean-centered rating $s_{uj}$** of a user $u$ for item $j$ is defined by subtracting her mean rating from the raw rating $r_{uj}$, \n",
    "\n",
    "$$ s_{uj} = r_{uj} - \\mu_{u} \\quad \\forall u \\in \\{1, \\cdots,  m\\}$$\n",
    "\n",
    "As before, the weighted average of the mean-centered rating of an item in the top-k peer\n",
    "group of target user $u$ is used to provide a **mean-centered prediction $\\hat{r}_{uj}$**. The mean rating of\n",
    "the target user is then added back to this prediction to provide a raw rating prediction $\\hat{r}_{uj}$ of target user $u$ for item $j$. The hat notation on top of $r_{uj}$ indicates a predicted rating, as opposed to one that was already observed in the original ratings matrix. \n",
    "\n",
    "Let $P_{u}(j)$ be the set of $k$ closest users to target user $u$, who have specified ratings for item $j$. Users with very low or negative correlations with target user $u$ are sometimes filtered from $P_{u}(j)$ as a heuristic enhancement. Then, the overall neighborhood-based prediction function is as follows:\n",
    "\n",
    "$$ \\hat{r}_{uj} = \\mu_{u} + \\frac{\\sum_{v \\in P_{u}(j)} Sim(u,v) \\cdot s_{vj}}{|\\sum_{v \\in P_{u}(j)} Sim(u,v) \\cdot s_{vj}|} $$\n",
    "\n",
    "This broader approach allows for a number of different variations in terms of how the similarity or prediction function is computed or in terms of which items are filtered out during the prediction process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Using Cornac`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm as notebook_tqdm\n",
    "import cornac\n",
    "from cornac.utils import cache\n",
    "from cornac.datasets import movielens\n",
    "from cornac.eval_methods import RatioSplit\n",
    "from cornac.models import UserKNN, ItemKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  ItemID  Rating\n",
       "0       1       1       7\n",
       "1       1       2       6\n",
       "2       1       3       7\n",
       "3       1       4       4\n",
       "4       1       5       5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = pd.read_csv(\n",
    "    cache(\"https://static.preferred.ai/tutorials/recommender-systems/sample_data.csv\"),\n",
    "    sep=\",\",\n",
    "    names=[\"UserID\", \"ItemID\", \"Rating\"],\n",
    ")\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = cornac.data.Dataset.from_uir(sample_df.itertuples(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 72315.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine(1,3) = 0.956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 21936.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson(1,3) = 0.894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "uknn_cosine = UserKNN(k=3, similarity=\"cosine\").fit(dataset)\n",
    "print(f\"Cosine(1,3) = {uknn_cosine.sim_mat[0, 2]:.3f}\")\n",
    "\n",
    "uknn_pearson = UserKNN(k=3, similarity=\"pearson\").fit(dataset)\n",
    "print(f\"Pearson(1,3) = {uknn_pearson.sim_mat[0, 2]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, to calculate the predicted rating given by *User 3* to *Item 1* and *Item 6*, where the ratings are based on the two nearest neighbors (*User 1* and *User 2*):\n",
    "\n",
    "\\begin{align*}\n",
    "\\hat{r}_{31} &= 2 + \\frac{1.5*0.894+1.2*0.939}{0.894 + 0.939} = 3.35 \\\\\n",
    "\\hat{r}_{36} &= 2 + \\frac{-1.5*0.894-0.8*0.939}{0.894 + 0.939} = 0.86\n",
    "\\end{align*}\n",
    "\n",
    "Let's validate the calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R(3,1) = 3.24\n",
      "R(3,6) = 0.90\n"
     ]
    }
   ],
   "source": [
    "print(f\"R(3,1) = {uknn_pearson.score(user_idx=2, item_idx=0):.2f}\")\n",
    "print(f\"R(3,6) = {uknn_pearson.score(user_idx=2, item_idx=5):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example ML-100**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now employ these algorithms on the [MovieLens](https://grouplens.org/datasets/movielens/) dataset. Our convention is to use the mean-centered ratings when aggregating the neighbors' ratings to produce a prediction and thereafter adjusting for the mean.  However, we can base the similarity computation based on either the original ratings or the mean-centered ratings, as shown in the variations below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "                   |   RMSE | Train (s) | Test (s)\n",
      "------------------ + ------ + --------- + --------\n",
      "UserKNN-Cosine     | 0.9041 |    0.0458 |   0.3485\n",
      "UserKNN-Cosine-MC  | 0.8955 |    0.0407 |   0.3489\n",
      "UserKNN-Pearson    | 0.8955 |    0.0416 |   0.3495\n",
      "UserKNN-Pearson-MC | 0.8955 |    0.0410 |   0.3437\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# UserKNN methods\n",
    "VERBOSE = False\n",
    "SEED = 29\n",
    "\n",
    "# number of nearest neighbors\n",
    "K = 50\n",
    "\n",
    "uknn_cosine = UserKNN(k=K, similarity=\"cosine\", name=\"UserKNN-Cosine\", verbose=VERBOSE)\n",
    "uknn_cosine_mc = UserKNN(\n",
    "    k=K,\n",
    "    similarity=\"cosine\",\n",
    "    mean_centered=True,\n",
    "    name=\"UserKNN-Cosine-MC\",\n",
    "    verbose=VERBOSE,\n",
    ")\n",
    "uknn_pearson = UserKNN(\n",
    "    k=K, similarity=\"pearson\", name=\"UserKNN-Pearson\", verbose=VERBOSE\n",
    ")\n",
    "uknn_pearson_mc = UserKNN(\n",
    "    k=K,\n",
    "    similarity=\"pearson\",\n",
    "    mean_centered=True,\n",
    "    name=\"UserKNN-Pearson-MC\",\n",
    "    verbose=VERBOSE,\n",
    ")\n",
    "\n",
    "feedback = movielens.load_feedback(variant=\"100K\")\n",
    "ratio_split = RatioSplit(feedback, test_size=0.1, seed=SEED, verbose=VERBOSE)\n",
    "cornac.Experiment(\n",
    "    eval_method=ratio_split,\n",
    "    models=[uknn_cosine, uknn_cosine_mc, uknn_pearson, uknn_pearson_mc],\n",
    "    metrics=[cornac.metrics.RMSE()],\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you notice that Cosine with mean-centering is similar to Pearson (with and without mean-centering)? Why is that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Kneighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\n",
    "    \"./ml-100k/u1.base\",\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"],\n",
    ")\n",
    "test_df = pd.read_csv(\n",
    "    \"./ml-100k/u1.test\",\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the ratings matrix\n",
    "ratings_matrix = pd.pivot_table(\n",
    "    train_df, values=\"rating\", index=\"user_id\", columns=\"item_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>1673</th>\n",
       "      <th>1674</th>\n",
       "      <th>1675</th>\n",
       "      <th>1676</th>\n",
       "      <th>1677</th>\n",
       "      <th>1678</th>\n",
       "      <th>1679</th>\n",
       "      <th>1680</th>\n",
       "      <th>1681</th>\n",
       "      <th>1682</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1650 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item_id  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
       "user_id                                                              ...   \n",
       "1         5.0   3.0   4.0   3.0   3.0   NaN   4.0   1.0   5.0   NaN  ...   \n",
       "2         4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   2.0  ...   \n",
       "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "5         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "\n",
       "item_id  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \n",
       "user_id                                                              \n",
       "1         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "5         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 1650 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_ratings_matrix = ratings_matrix.subtract(ratings_matrix.mean(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we use Pearson correlation to measure how similar items or users are. But if we were using cosine similarity, we would need to deal with any missing ratings. The usual way to do this is to fill in the missing spots with the average rating that a user gives to all items or the average rating that all users give to an item. Some people might just put a 0 in the missing spots, which is okay as long as we've made sure all the data is on a common scale first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>user_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>934</th>\n",
       "      <th>935</th>\n",
       "      <th>936</th>\n",
       "      <th>937</th>\n",
       "      <th>938</th>\n",
       "      <th>939</th>\n",
       "      <th>940</th>\n",
       "      <th>941</th>\n",
       "      <th>942</th>\n",
       "      <th>943</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.26968</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.147833</td>\n",
       "      <td>0.298108</td>\n",
       "      <td>0.234765</td>\n",
       "      <td>0.870864</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.080917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>-0.319444</td>\n",
       "      <td>0.203564</td>\n",
       "      <td>-0.235457</td>\n",
       "      <td>0.551592</td>\n",
       "      <td>2.422705e-17</td>\n",
       "      <td>0.210060</td>\n",
       "      <td>0.679366</td>\n",
       "      <td>-0.193489</td>\n",
       "      <td>0.243038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.269680</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.484802</td>\n",
       "      <td>0.763590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>-0.516398</td>\n",
       "      <td>0.293674</td>\n",
       "      <td>0.618042</td>\n",
       "      <td>0.170254</td>\n",
       "      <td>1.740777e-01</td>\n",
       "      <td>-0.129460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.259437</td>\n",
       "      <td>0.627495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.694365</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.186551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.086207</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.648886</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.188982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.258199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.836056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.327327</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.147833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025565</td>\n",
       "      <td>0.237864</td>\n",
       "      <td>0.270501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.159901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293481</td>\n",
       "      <td>-0.522233</td>\n",
       "      <td>-0.080582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.568360</td>\n",
       "      <td>8.944272e-01</td>\n",
       "      <td>0.039459</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.233984</td>\n",
       "      <td>0.396352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 943 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "user_id       1        2    3    4         5         6         7         8    \\\n",
       "user_id                                                                        \n",
       "1        1.000000  0.26968  0.5  NaN  0.147833  0.298108  0.234765  0.870864   \n",
       "2        0.269680  1.00000  NaN  NaN       NaN  0.484802  0.763590       NaN   \n",
       "3        0.500000      NaN  1.0  0.0       NaN -0.694365       NaN  0.500000   \n",
       "4             NaN      NaN  0.0  1.0       NaN       NaN -0.188982  1.000000   \n",
       "5        0.147833      NaN  NaN  NaN  1.000000  0.025565  0.237864  0.270501   \n",
       "\n",
       "user_id  9         10   ...       934       935       936       937       938  \\\n",
       "user_id                 ...                                                     \n",
       "1        1.0 -0.080917  ...  0.008439 -0.319444  0.203564 -0.235457  0.551592   \n",
       "2        NaN       NaN  ...  0.400000 -0.516398  0.293674  0.618042  0.170254   \n",
       "3        NaN       NaN  ...       NaN       NaN -0.186551  0.000000 -0.166667   \n",
       "4        NaN       NaN  ...       NaN       NaN -0.200000       NaN  0.258199   \n",
       "5        NaN -0.159901  ...  0.293481 -0.522233 -0.080582       NaN  0.568360   \n",
       "\n",
       "user_id           939       940       941       942       943  \n",
       "user_id                                                        \n",
       "1        2.422705e-17  0.210060  0.679366 -0.193489  0.243038  \n",
       "2        1.740777e-01 -0.129460  0.000000  0.259437  0.627495  \n",
       "3                 NaN -0.086207  1.000000  0.648886       NaN  \n",
       "4                 NaN  0.836056  1.000000  0.327327       NaN  \n",
       "5        8.944272e-01  0.039459  0.577350  0.233984  0.396352  \n",
       "\n",
       "[5 rows x 943 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix = normalized_ratings_matrix.T.corr()\n",
    "similarity_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to calculate the score (rating) according to the formula we saw in the previous section. It’s worth noting that not all the items in the test set are found in the training set. In this case, we use 2.5 since it’s neutral (could use the average rating of the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(user_id, item_id):\n",
    "    \"\"\"\n",
    "    Calculate the predicted rating for a given user and item using a weighted average approach.\n",
    "\n",
    "    Args:\n",
    "    user_id: The ID of the user.\n",
    "    item_id: The ID of the item.\n",
    "\n",
    "    Returns:\n",
    "    The predicted rating for the item by the user.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the item exists in the ratings matrix; if not, return a default score of 2.5\n",
    "    if item_id not in ratings_matrix.columns:\n",
    "        return 2.5\n",
    "\n",
    "    # Get similarity scores for all users with respect to the current user, excluding the user themselves\n",
    "    similarity_scores = similarity_matrix[user_id].drop(labels=user_id)\n",
    "\n",
    "    # Get the normalized ratings for the item, excluding the current user's rating\n",
    "    normalized_ratings = normalized_ratings_matrix[item_id].drop(index=user_id)\n",
    "\n",
    "    # Exclude users who haven't rated the item from both similarity scores and normalized ratings\n",
    "    users_with_missing_ratings = normalized_ratings[normalized_ratings.isnull()].index\n",
    "    similarity_scores.drop(index=users_with_missing_ratings, inplace=True)\n",
    "    normalized_ratings.dropna(inplace=True)\n",
    "\n",
    "    # If no other users have rated items in common with the current user, return a default score\n",
    "    if similarity_scores.empty:\n",
    "        return 2\n",
    "\n",
    "    # Initialize accumulators for the total score and total weight\n",
    "    total_score = 0\n",
    "    total_weight = 0\n",
    "\n",
    "    # Calculate the weighted score for each user who has rated the item\n",
    "    for other_user_id in normalized_ratings.index:\n",
    "        if not pd.isna(similarity_scores[other_user_id]):\n",
    "            total_score += (\n",
    "                normalized_ratings[other_user_id] * similarity_scores[other_user_id]\n",
    "            )\n",
    "            total_weight += abs(similarity_scores[other_user_id])\n",
    "\n",
    "    # If no weights are available, return the user's average rating across all items\n",
    "    if total_weight == 0:\n",
    "        return ratings_matrix.T.mean()[user_id]\n",
    "\n",
    "    # Calculate the predicted rating based on the weighted average of ratings\n",
    "    predicted_rating = ratings_matrix.T.mean()[user_id] + total_score / total_weight\n",
    "\n",
    "    return predicted_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We iterate over all the user/item pairs in the test set and calculate the prediction using the function defined previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 0.9723785192883043\n"
     ]
    }
   ],
   "source": [
    "# Extract actual ratings from the test dataset\n",
    "test_ratings = np.array(test_df[\"rating\"])\n",
    "\n",
    "# Create an iterator for user-item pairs for prediction\n",
    "user_item_pairs = zip(test_df[\"user_id\"], test_df[\"item_id\"])\n",
    "\n",
    "# Use list comprehension for efficient prediction of ratings\n",
    "# Calculate predicted ratings for each user-item pair using the improved calculate_score function\n",
    "pred_ratings = np.array(\n",
    "    [calculate_score(user_id, item_id) for user_id, item_id in user_item_pairs]\n",
    ")\n",
    "\n",
    "# Calculate the root mean squared error (RMSE) between actual and predicted ratings\n",
    "rmse = np.sqrt(mean_squared_error(test_ratings, pred_ratings))\n",
    "\n",
    "# Print the RMSE to evaluate the performance of the recommendation system\n",
    "print(f\"Root Mean Squared Error: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User-based collaborative filtering is an effective way to come up for recommendations. That being said, it suffers from issues of sparsity. In other words, you tend to encounter a large number of items and a relatively small number of ratings which results in a lot of wasted memory space. Not to mention, when we start dealing with millions of users, computing all pairwise correlations becomes very expensive. \n",
    "\n",
    "To get around this issue, we can do the method of using a subset of users, k nearest neighbourhood, and use that when computing the rating with conrac library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1.2 Item-based models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *Cosine* and *Pearson* similarities can be applied for item-based methods as well, except that the feature vectors are now columns instead of rows as we measure similarity between items. \n",
    "\n",
    "If *Cosine* similarity is based on the mean-centered rating matrix, we have a variant called *AdjustedCosine*.  The *adjusted* cosine similarity between the items (columns) *i* and *j* is defined as follows:\n",
    "\n",
    "$$ \\mathrm{AdjustedCosine}(i,j) = \\frac{\\Sigma_{u \\in \\mathcal{U}_i \\cap \\mathcal{U}_j} s_{ui} * s_{uj}}{\\sqrt{\\Sigma_{u \\in \\mathcal{U}_i \\cap \\mathcal{U}_j} s_{ui}^2} * \\sqrt{\\Sigma_{u \\in \\mathcal{U}_i \\cap \\mathcal{U}_j} s_{uj}^2}} $$\n",
    "\n",
    "where $s_{ui}$ is the mean-centered rating that user $u$ gives to item $i$. \n",
    "\n",
    "For example, we calculate *adjusted* cosine between *Item 1* and *Item 3* in the small sample dataset from before:\n",
    "\n",
    "$$ \\mathrm{AdjustedCosine}(1,3) = \\frac{1.5 * 1.5 + (-1.5) * (-0.5) + (-1) * (-1)}{\\sqrt{1.5^2 + (-1.5)^2 + (-1)^2} * \\sqrt{1.5^2 + (-0.5)^2 + (-1)^2}} = 0.912 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdjustedCosine(1,3) = 0.912\n"
     ]
    }
   ],
   "source": [
    "iknn_adj = ItemKNN(k=2, similarity=\"cosine\", mean_centered=True, verbose=VERBOSE).fit(\n",
    "    dataset\n",
    ")\n",
    "print(f\"AdjustedCosine(1,3) = {iknn_adj.sim_mat[0, 2]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For prediction, we use the same form of prediction function as in user-based methods but aggregate the user's ratings on neighboring items:\n",
    "\n",
    "$$ \\hat{r}_{ut} = \\mu_u + \\frac{\\Sigma_{j \\in Q_t(u)} \\mathrm{Sim}(j,t) * (r_{uj} - \\mu_u)}{\\Sigma_{j \\in Q_t(u)} |\\mathrm{Sim}(j,t)|} $$\n",
    "\n",
    "\n",
    "For example, below we predict the ratings that *User 3* would give to *Item 1* and *Item 6*. The rating for *Item 1* is based on two nearest neighbors *Item 2* and *Item 3*, while the rating for *Item 6* is based on *Item 4* and *Item 5*.\n",
    "\n",
    "\\begin{align*}\n",
    "\\hat{r}_{31} &= 2 + \\frac{1*0.735 + 1*0.912}{0.735 + 0.912} = 3 \\\\\n",
    "\\hat{r}_{36} &= 2 + \\frac{(-1)*0.829 + (-1)*0.730}{0.829 + 0.730} = 1\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R(3,1) = 3.0\n",
      "R(3,6) = 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"R(3,1) = {iknn_adj.score(user_idx=2, item_idx=0):.1f}\")\n",
    "print(f\"R(3,6) = {iknn_adj.score(user_idx=2, item_idx=5):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example ML-100**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "                       |   RMSE | Train (s) | Test (s)\n",
      "---------------------- + ------ + --------- + --------\n",
      "ItemKNN-Cosine         | 0.9721 |    0.0850 |   0.3821\n",
      "ItemKNN-Pearson        | 0.9640 |    0.0871 |   0.3774\n",
      "ItemKNN-Pearson-MC     | 0.9554 |    0.0890 |   0.3784\n",
      "ItemKNN-AdjustedCosine | 0.9060 |    0.0818 |   0.3892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ItemKNN methods\n",
    "\n",
    "K = 50  # number of nearest neighbors\n",
    "\n",
    "iknn_cosine = ItemKNN(k=K, similarity=\"cosine\", name=\"ItemKNN-Cosine\", verbose=VERBOSE)\n",
    "iknn_pearson = ItemKNN(\n",
    "    k=K, similarity=\"pearson\", name=\"ItemKNN-Pearson\", verbose=VERBOSE\n",
    ")\n",
    "iknn_pearson_mc = ItemKNN(\n",
    "    k=K,\n",
    "    similarity=\"pearson\",\n",
    "    mean_centered=True,\n",
    "    name=\"ItemKNN-Pearson-MC\",\n",
    "    verbose=VERBOSE,\n",
    ")\n",
    "iknn_adjusted = ItemKNN(\n",
    "    k=K,\n",
    "    similarity=\"cosine\",\n",
    "    mean_centered=True,\n",
    "    name=\"ItemKNN-AdjustedCosine\",\n",
    "    verbose=VERBOSE,\n",
    ")\n",
    "\n",
    "feedback = movielens.load_feedback(variant=\"100K\")\n",
    "ratio_split = RatioSplit(feedback, test_size=0.1, seed=SEED, verbose=VERBOSE)\n",
    "cornac.Experiment(\n",
    "    eval_method=ratio_split,\n",
    "    models=[iknn_cosine, iknn_pearson, iknn_pearson_mc, iknn_adjusted],\n",
    "    metrics=[cornac.metrics.RMSE()],\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Similarity Reweighting**\n",
    "\n",
    "\n",
    "Given that our similarities are either *Cosine* or *Pearson*, which lie in the range $[-1, 1]$, the rating values may vary in different scales on different platforms.  One common practice to increase the *relative* importance of the similarity scores is exponential amplification.  For example, a new amplified similarity score based on *Pearson* correlation is:\n",
    "\n",
    "$$ \\mathrm{Sim}(u, v) = \\mathrm{Pearson}(u, v)^{\\mathrm{amplify}} $$\n",
    "\n",
    "\n",
    "Another issue is the long-tailed distribution of the items.  Some items might be very popular and tend to be less discriminative across different users.  This phenomenon is also very common in the information retrieval (IR) literature.  Thus, we can borrow some techniques for feature reweighting from IR.  One of them is the notion of *Inverse Document Frequency (idf)*, part of [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf), where the score of each item $i$ can be reweighted as:\n",
    "\n",
    "$$ w_i = \\log \\bigg( \\frac{N}{m_i} \\bigg), $$\n",
    "\n",
    "$N$ is the number of users and $m_i$ is the number of ratings of item $i$. This formula decreases the weight of items that appear in many users’ lists, making less common items relatively more important, hence helping in discriminating between different users' preferences more effectively.\n",
    "\n",
    "We also have [Okapi BM25](https://en.wikipedia.org/wiki/Okapi_BM25), which is an improved version of TF-IDF, implemented inside the Cornac library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "               |   RMSE | Train (s) | Test (s)\n",
      "-------------- + ------ + --------- + --------\n",
      "UserKNN-Base   | 0.8955 |    0.0483 |   0.3525\n",
      "UserKNN-Amp0.5 | 0.8954 |    0.1577 |   0.3468\n",
      "UserKNN-Amp3.0 | 0.9097 |    0.1574 |   0.3511\n",
      "UserKNN-IDF    | 0.8951 |    0.0420 |   0.3489\n",
      "UserKNN-BM25   | 0.8951 |    0.0435 |   0.3493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# UserKNN methods\n",
    "K = 50  # number of nearest neighbors\n",
    "uknn_base = UserKNN(k=K, similarity=\"pearson\", name=\"UserKNN-Base\", verbose=VERBOSE)\n",
    "uknn_amp1 = UserKNN(\n",
    "    k=K, similarity=\"pearson\", amplify=0.5, name=\"UserKNN-Amp0.5\", verbose=VERBOSE\n",
    ")\n",
    "uknn_amp2 = UserKNN(\n",
    "    k=K, similarity=\"pearson\", amplify=3.0, name=\"UserKNN-Amp3.0\", verbose=VERBOSE\n",
    ")\n",
    "uknn_idf = UserKNN(\n",
    "    k=K, similarity=\"pearson\", weighting=\"idf\", name=\"UserKNN-IDF\", verbose=VERBOSE\n",
    ")\n",
    "uknn_bm25 = UserKNN(\n",
    "    k=K, similarity=\"pearson\", weighting=\"bm25\", name=\"UserKNN-BM25\", verbose=VERBOSE\n",
    ")\n",
    "\n",
    "feedback = movielens.load_feedback(variant=\"100K\")\n",
    "ratio_split = RatioSplit(feedback, test_size=0.1, seed=SEED, verbose=VERBOSE)\n",
    "cornac.Experiment(\n",
    "    eval_method=ratio_split,\n",
    "    models=[uknn_base, uknn_amp1, uknn_amp2, uknn_idf, uknn_bm25],\n",
    "    metrics=[cornac.metrics.RMSE()],\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Interpreting Recommendations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of rating prediction being a black-box task, most of us would find it useful to be able to better understand why certain recommendations are being made.  In an effort to better interpret the recommendation results, we can look to various sources, such as the metadata, the contribution of each neighbor, as well as the interaction between the user and the neighboring items.\n",
    "\n",
    "The MovieLens 100K dataset comes with some forms of [metadata](http://files.grouplens.org/datasets/movielens/ml-100k-README.txt).  We can refer to that metadata to uncover more information on the recommendations.  Below we will take a look at the movie title and genres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download some information of MovieLens 100K dataset\n",
    "user_df = pd.read_csv(\n",
    "    cache(\"http://files.grouplens.org/datasets/movielens/ml-100k/u.user\"),\n",
    "    sep=\"|\",\n",
    "    names=[\"UserID\", \"Age\", \"Gender\", \"Occupation\", \"Zip Code\"],\n",
    ").set_index(\"UserID\")\n",
    "\n",
    "item_df = (\n",
    "    pd.read_csv(\n",
    "        cache(\"http://files.grouplens.org/datasets/movielens/ml-100k/u.item\"),\n",
    "        sep=\"|\",\n",
    "        encoding=\"ISO-8859-1\",\n",
    "        names=[\n",
    "            \"ItemID\",\n",
    "            \"Title\",\n",
    "            \"Release Date\",\n",
    "            \"Video Release Date\",\n",
    "            \"IMDb URL\",\n",
    "            \"unknown\",\n",
    "            \"Action\",\n",
    "            \"Adventure\",\n",
    "            \"Animation\",\n",
    "            \"Children's\",\n",
    "            \"Comedy\",\n",
    "            \"Crime\",\n",
    "            \"Documentary\",\n",
    "            \"Drama\",\n",
    "            \"Fantasy\",\n",
    "            \"Film-Noir\",\n",
    "            \"Horror\",\n",
    "            \"Musical\",\n",
    "            \"Mystery\",\n",
    "            \"Romance\",\n",
    "            \"Sci-Fi\",\n",
    "            \"Thriller\",\n",
    "            \"War\",\n",
    "            \"Western\",\n",
    "        ],\n",
    "    )\n",
    "    .set_index(\"ItemID\")\n",
    "    .drop(columns=[\"Video Release Date\", \"IMDb URL\", \"unknown\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UserKNN (Pearson)\n",
    "\n",
    "For UserKNN methods, we use the *Pearson* variant as our recommender system.  \n",
    "First, let's select a user to explore her profile as well as her highly rated items in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserID = 1\n",
      "-------------------------\n",
      "Age                   24\n",
      "Gender                 M\n",
      "Occupation    technician\n",
      "Zip Code           85711\n",
      "Name: 1, dtype: object\n",
      "\n",
      "TOP 5 RATED ITEMS BY USER 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children's</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Graduate, The (1967)</td>\n",
       "      <td>01-Jan-1967</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Mystery Science Theater 3000: The Movie (1996)</td>\n",
       "      <td>19-Apr-1996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Truth About Cats &amp; Dogs, The (1996)</td>\n",
       "      <td>26-Apr-1996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Delicatessen (1991)</td>\n",
       "      <td>01-Jan-1991</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Terminator 2: Judgment Day (1991)</td>\n",
       "      <td>01-Jan-1991</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title Release Date  Action  \\\n",
       "ItemID                                                                        \n",
       "197                               Graduate, The (1967)  01-Jan-1967       0   \n",
       "109     Mystery Science Theater 3000: The Movie (1996)  19-Apr-1996       0   \n",
       "111                Truth About Cats & Dogs, The (1996)  26-Apr-1996       0   \n",
       "171                                Delicatessen (1991)  01-Jan-1991       0   \n",
       "96                   Terminator 2: Judgment Day (1991)  01-Jan-1991       1   \n",
       "\n",
       "        Adventure  Animation  Children's  Comedy  Crime  Documentary  Drama  \\\n",
       "ItemID                                                                        \n",
       "197             0          0           0       0      0            0      1   \n",
       "109             0          0           0       1      0            0      0   \n",
       "111             0          0           0       1      0            0      0   \n",
       "171             0          0           0       1      0            0      0   \n",
       "96              0          0           0       0      0            0      0   \n",
       "\n",
       "        Fantasy  Film-Noir  Horror  Musical  Mystery  Romance  Sci-Fi  \\\n",
       "ItemID                                                                  \n",
       "197           0          0       0        0        0        1       0   \n",
       "109           0          0       0        0        0        0       1   \n",
       "111           0          0       0        0        0        1       0   \n",
       "171           0          0       0        0        0        0       1   \n",
       "96            0          0       0        0        0        0       1   \n",
       "\n",
       "        Thriller  War  Western  \n",
       "ItemID                          \n",
       "197            0    0        0  \n",
       "109            0    0        0  \n",
       "111            0    0        0  \n",
       "171            0    0        0  \n",
       "96             1    0        0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_mat = uknn_pearson.train_set.matrix\n",
    "user_id2idx = uknn_pearson.train_set.uid_map\n",
    "user_idx2id = list(uknn_pearson.train_set.user_ids)\n",
    "item_id2idx = uknn_pearson.train_set.iid_map\n",
    "item_idx2id = list(uknn_pearson.train_set.item_ids)\n",
    "\n",
    "TOPK = 5\n",
    "UID = 1\n",
    "UIDX = uknn_pearson.train_set.uid_map[str(UID)]\n",
    "\n",
    "print(f\"UserID = {UID}\")\n",
    "print(\"-\" * 25)\n",
    "print(user_df.loc[UID])\n",
    "\n",
    "rating_arr = rating_mat[UIDX].A.ravel()\n",
    "top_rated_items = np.argsort(rating_arr)[-TOPK:]\n",
    "print(f\"\\nTOP {TOPK} RATED ITEMS BY USER {UID}:\")\n",
    "item_df.loc[[int(item_idx2id[i]) for i in top_rated_items]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserID = 2\n",
      "-------------------------\n",
      "Age              53\n",
      "Gender            F\n",
      "Occupation    other\n",
      "Zip Code      94043\n",
      "Name: 2, dtype: object\n",
      "\n",
      "TOP 5 RATED ITEMS BY USER 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children's</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>Titanic (1997)</td>\n",
       "      <td>01-Jan-1997</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Shall We Dance? (1996)</td>\n",
       "      <td>11-Jul-1997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>As Good As It Gets (1997)</td>\n",
       "      <td>23-Dec-1997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Emma (1996)</td>\n",
       "      <td>02-Aug-1996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Star Wars (1977)</td>\n",
       "      <td>01-Jan-1977</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Title Release Date  Action  Adventure  Animation  \\\n",
       "ItemID                                                                         \n",
       "313                Titanic (1997)  01-Jan-1997       1          0          0   \n",
       "251        Shall We Dance? (1996)  11-Jul-1997       0          0          0   \n",
       "316     As Good As It Gets (1997)  23-Dec-1997       0          0          0   \n",
       "283                   Emma (1996)  02-Aug-1996       0          0          0   \n",
       "50               Star Wars (1977)  01-Jan-1977       1          1          0   \n",
       "\n",
       "        Children's  Comedy  Crime  Documentary  Drama  Fantasy  Film-Noir  \\\n",
       "ItemID                                                                      \n",
       "313              0       0      0            0      1        0          0   \n",
       "251              0       1      0            0      0        0          0   \n",
       "316              0       1      0            0      1        0          0   \n",
       "283              0       0      0            0      1        0          0   \n",
       "50               0       0      0            0      0        0          0   \n",
       "\n",
       "        Horror  Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       "ItemID                                                                     \n",
       "313          0        0        0        1       0         0    0        0  \n",
       "251          0        0        0        0       0         0    0        0  \n",
       "316          0        0        0        0       0         0    0        0  \n",
       "283          0        0        0        1       0         0    0        0  \n",
       "50           0        0        0        1       1         0    1        0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOPK = 5\n",
    "UID = 2\n",
    "UIDX = uknn_pearson.train_set.uid_map[str(UID)]\n",
    "\n",
    "print(f\"UserID = {UID}\")\n",
    "print(\"-\" * 25)\n",
    "print(user_df.loc[UID])\n",
    "\n",
    "rating_arr = rating_mat[UIDX].A.ravel()\n",
    "top_rated_items = np.argsort(rating_arr)[-TOPK:]\n",
    "print(f\"\\nTOP {TOPK} RATED ITEMS BY USER {UID}:\")\n",
    "item_df.loc[[int(item_idx2id[i]) for i in top_rated_items]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, among the top 5 rated movies observed for *User 1*, 2 of them are Drama movies.\n",
    "\n",
    "Recommendations for this user can be obtained as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TOP 5 RECOMMENDATIONS FOR USER 2:\n",
      "Scores: [6.29454539 5.90842028 5.75086209 5.61197227 5.41307687]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children's</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>Tough and Deadly (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>Mat' i syn (1997)</td>\n",
       "      <td>06-Feb-1998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>Rough Magic (1995)</td>\n",
       "      <td>30-May-1997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>Great Day in Harlem, A (1994)</td>\n",
       "      <td>01-Jan-1994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>Naked in New York (1994)</td>\n",
       "      <td>01-Jan-1994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Title Release Date  Action  Adventure  \\\n",
       "ItemID                                                                  \n",
       "1491          Tough and Deadly (1995)  01-Jan-1995       1          0   \n",
       "1678                Mat' i syn (1997)  06-Feb-1998       0          0   \n",
       "1662               Rough Magic (1995)  30-May-1997       0          0   \n",
       "814     Great Day in Harlem, A (1994)  01-Jan-1994       0          0   \n",
       "1502         Naked in New York (1994)  01-Jan-1994       0          0   \n",
       "\n",
       "        Animation  Children's  Comedy  Crime  Documentary  Drama  Fantasy  \\\n",
       "ItemID                                                                      \n",
       "1491            0           0       0      0            0      1        0   \n",
       "1678            0           0       0      0            0      1        0   \n",
       "1662            0           0       0      0            0      1        0   \n",
       "814             0           0       0      0            1      0        0   \n",
       "1502            0           0       1      0            0      0        0   \n",
       "\n",
       "        Film-Noir  Horror  Musical  Mystery  Romance  Sci-Fi  Thriller  War  \\\n",
       "ItemID                                                                        \n",
       "1491            0       0        0        0        0       0         1    0   \n",
       "1678            0       0        0        0        0       0         0    0   \n",
       "1662            0       0        0        0        1       0         0    0   \n",
       "814             0       0        0        0        0       0         0    0   \n",
       "1502            0       0        0        0        1       0         0    0   \n",
       "\n",
       "        Western  \n",
       "ItemID           \n",
       "1491          0  \n",
       "1678          0  \n",
       "1662          0  \n",
       "814           0  \n",
       "1502          0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations, scores = uknn_pearson.rank(UIDX)\n",
    "print(f\"\\nTOP {TOPK} RECOMMENDATIONS FOR USER {UID}:\")\n",
    "print(\"Scores:\", scores[recommendations[:TOPK]])\n",
    "item_df.loc[[int(item_idx2id[i]) for i in recommendations[:TOPK]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is intriguing, and perhaps revealing that of the five predicted movies, three of them are Drama movies.\n",
    "\n",
    "To better understand the nature of this recommendation, we would like to see how the nearest neighbors of the user contribute towards the prediction of each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommendation</th>\n",
       "      <th>User NN</th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Score by the NN</th>\n",
       "      <th>Contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tough and Deadly (1995)</td>\n",
       "      <td>125</td>\n",
       "      <td>-0.398416</td>\n",
       "      <td>-2.554545</td>\n",
       "      <td>2.554545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mat' i syn (1997)</td>\n",
       "      <td>396</td>\n",
       "      <td>-0.027963</td>\n",
       "      <td>-2.168421</td>\n",
       "      <td>2.168421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rough Magic (1995)</td>\n",
       "      <td>198</td>\n",
       "      <td>0.095309</td>\n",
       "      <td>1.214286</td>\n",
       "      <td>1.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Great Day in Harlem, A (1994)</td>\n",
       "      <td>37</td>\n",
       "      <td>0.422981</td>\n",
       "      <td>1.871972</td>\n",
       "      <td>1.871972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naked in New York (1994)</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.297855</td>\n",
       "      <td>-1.673077</td>\n",
       "      <td>1.673077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Recommendation  User NN  Similarity  Score by the NN  \\\n",
       "0        Tough and Deadly (1995)      125   -0.398416        -2.554545   \n",
       "1              Mat' i syn (1997)      396   -0.027963        -2.168421   \n",
       "2             Rough Magic (1995)      198    0.095309         1.214286   \n",
       "3  Great Day in Harlem, A (1994)       37    0.422981         1.871972   \n",
       "4       Naked in New York (1994)       25   -0.297855        -1.673077   \n",
       "\n",
       "   Contribution  \n",
       "0      2.554545  \n",
       "1      2.168421  \n",
       "2      1.214286  \n",
       "3      1.871972  \n",
       "4      1.673077  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "df = defaultdict(list)\n",
    "sim_arr = uknn_pearson.sim_mat[UIDX].A.ravel()\n",
    "for rec in recommendations[:TOPK]:\n",
    "    rated_users = np.array([u for u in range(len(sim_arr)) if rating_mat[u, rec] != 0])\n",
    "    nearest_neighbor = rated_users[np.argsort(sim_arr[rated_users])[-1:]].item()\n",
    "    sim = sim_arr[nearest_neighbor]\n",
    "    score = uknn_pearson.iu_mat[rec, nearest_neighbor]\n",
    "    df[\"Recommendation\"].append(item_df.loc[[int(item_idx2id[rec])]][\"Title\"].values[0])\n",
    "    df[\"User NN\"].append(nearest_neighbor)\n",
    "    df[\"Similarity\"].append(sim)\n",
    "    df[\"Score by the NN\"].append(score)\n",
    "    df[\"Contribution\"].append((score * sim) / np.abs(sim))\n",
    "pd.DataFrame.from_dict(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, for the first movie recommendation, the nearest-neighbor of the user is the one having negative similarity with the user and giving a negative rating to the item as well.  The double negatives result in a positive contribution!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ItemKNN (AdjustedCosine)\n",
    "\n",
    "For ItemKNN methods, we take the *AdjustedCosine* variant as our recommender system.  Let's pick a user and see her top-K highly rated items. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserID = 1\n",
      "-------------------------\n",
      "Age                   24\n",
      "Gender                 M\n",
      "Occupation    technician\n",
      "Zip Code           85711\n",
      "Name: 1, dtype: object\n",
      "\n",
      "TOP 5 RATED ITEMS BY USER 1:\n",
      "Ratings: [5. 5. 5. 5. 5.]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children's</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Graduate, The (1967)</td>\n",
       "      <td>01-Jan-1967</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Mystery Science Theater 3000: The Movie (1996)</td>\n",
       "      <td>19-Apr-1996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Truth About Cats &amp; Dogs, The (1996)</td>\n",
       "      <td>26-Apr-1996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Delicatessen (1991)</td>\n",
       "      <td>01-Jan-1991</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Terminator 2: Judgment Day (1991)</td>\n",
       "      <td>01-Jan-1991</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title Release Date  Action  \\\n",
       "ItemID                                                                        \n",
       "197                               Graduate, The (1967)  01-Jan-1967       0   \n",
       "109     Mystery Science Theater 3000: The Movie (1996)  19-Apr-1996       0   \n",
       "111                Truth About Cats & Dogs, The (1996)  26-Apr-1996       0   \n",
       "171                                Delicatessen (1991)  01-Jan-1991       0   \n",
       "96                   Terminator 2: Judgment Day (1991)  01-Jan-1991       1   \n",
       "\n",
       "        Adventure  Animation  Children's  Comedy  Crime  Documentary  Drama  \\\n",
       "ItemID                                                                        \n",
       "197             0          0           0       0      0            0      1   \n",
       "109             0          0           0       1      0            0      0   \n",
       "111             0          0           0       1      0            0      0   \n",
       "171             0          0           0       1      0            0      0   \n",
       "96              0          0           0       0      0            0      0   \n",
       "\n",
       "        Fantasy  Film-Noir  Horror  Musical  Mystery  Romance  Sci-Fi  \\\n",
       "ItemID                                                                  \n",
       "197           0          0       0        0        0        1       0   \n",
       "109           0          0       0        0        0        0       1   \n",
       "111           0          0       0        0        0        1       0   \n",
       "171           0          0       0        0        0        0       1   \n",
       "96            0          0       0        0        0        0       1   \n",
       "\n",
       "        Thriller  War  Western  \n",
       "ItemID                          \n",
       "197            0    0        0  \n",
       "109            0    0        0  \n",
       "111            0    0        0  \n",
       "171            0    0        0  \n",
       "96             1    0        0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_mat = iknn_adjusted.train_set.matrix\n",
    "user_id2idx = iknn_adjusted.train_set.uid_map\n",
    "user_idx2id = list(iknn_adjusted.train_set.user_ids)\n",
    "item_id2idx = iknn_adjusted.train_set.iid_map\n",
    "item_idx2id = list(iknn_adjusted.train_set.item_ids)\n",
    "\n",
    "TOPK = 5\n",
    "UID = 1\n",
    "UIDX = user_id2idx[str(UID)]\n",
    "\n",
    "print(f\"UserID = {UID}\")\n",
    "print(\"-\" * 25)\n",
    "print(user_df.loc[UID])\n",
    "\n",
    "rating_arr = rating_mat[UIDX].A.ravel()\n",
    "top_rated_items = np.argsort(rating_arr)[-TOPK:]\n",
    "print(f\"\\nTOP {TOPK} RATED ITEMS BY USER {UID}:\")\n",
    "print(\"Ratings:\", rating_arr[top_rated_items])\n",
    "item_df.loc[[int(item_idx2id[i]) for i in top_rated_items]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TOP 5 RECOMMENDATIONS FOR USER 1:\n",
      "Scores: [4.66730267 4.65414463 4.64983031 4.63932431 4.63775818]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children's</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Horseman on the Roof, The (Hussard sur le toit...</td>\n",
       "      <td>19-Apr-1996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Chasing Amy (1997)</td>\n",
       "      <td>01-Jan-1997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Empire Strikes Back, The (1980)</td>\n",
       "      <td>01-Jan-1980</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Manon of the Spring (Manon des sources) (1986)</td>\n",
       "      <td>01-Jan-1986</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Nikita (La Femme Nikita) (1990)</td>\n",
       "      <td>01-Jan-1990</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Title Release Date  \\\n",
       "ItemID                                                                   \n",
       "113     Horseman on the Roof, The (Hussard sur le toit...  19-Apr-1996   \n",
       "246                                    Chasing Amy (1997)  01-Jan-1997   \n",
       "172                       Empire Strikes Back, The (1980)  01-Jan-1980   \n",
       "166        Manon of the Spring (Manon des sources) (1986)  01-Jan-1986   \n",
       "198                       Nikita (La Femme Nikita) (1990)  01-Jan-1990   \n",
       "\n",
       "        Action  Adventure  Animation  Children's  Comedy  Crime  Documentary  \\\n",
       "ItemID                                                                         \n",
       "113          0          0          0           0       0      0            0   \n",
       "246          0          0          0           0       0      0            0   \n",
       "172          1          1          0           0       0      0            0   \n",
       "166          0          0          0           0       0      0            0   \n",
       "198          0          0          0           0       0      0            0   \n",
       "\n",
       "        Drama  Fantasy  Film-Noir  Horror  Musical  Mystery  Romance  Sci-Fi  \\\n",
       "ItemID                                                                         \n",
       "113         1        0          0       0        0        0        0       0   \n",
       "246         1        0          0       0        0        0        1       0   \n",
       "172         1        0          0       0        0        0        1       1   \n",
       "166         1        0          0       0        0        0        0       0   \n",
       "198         0        0          0       0        0        0        0       0   \n",
       "\n",
       "        Thriller  War  Western  \n",
       "ItemID                          \n",
       "113            0    0        0  \n",
       "246            0    0        0  \n",
       "172            0    1        0  \n",
       "166            0    0        0  \n",
       "198            1    0        0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations, scores = iknn_adjusted.rank(UIDX)\n",
    "print(f\"\\nTOP {TOPK} RECOMMENDATIONS FOR USER {UID}:\")\n",
    "print(\"Scores:\", scores[recommendations[:TOPK]])\n",
    "item_df.loc[[int(item_idx2id[i]) for i in recommendations[:TOPK]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how the nearest-neighbor of each recommended item contributes towards the final scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommendation</th>\n",
       "      <th>Item NN</th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Score of the NN</th>\n",
       "      <th>Contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Horseman on the Roof, The (Hussard sur le toit...</td>\n",
       "      <td>562</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.399209</td>\n",
       "      <td>1.399209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chasing Amy (1997)</td>\n",
       "      <td>374</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.399209</td>\n",
       "      <td>1.399209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Empire Strikes Back, The (1980)</td>\n",
       "      <td>625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.399209</td>\n",
       "      <td>1.399209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manon of the Spring (Manon des sources) (1986)</td>\n",
       "      <td>936</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.399209</td>\n",
       "      <td>1.399209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nikita (La Femme Nikita) (1990)</td>\n",
       "      <td>142</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.399209</td>\n",
       "      <td>1.399209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Recommendation  Item NN  Similarity  \\\n",
       "0  Horseman on the Roof, The (Hussard sur le toit...      562         1.0   \n",
       "1                                 Chasing Amy (1997)      374         1.0   \n",
       "2                    Empire Strikes Back, The (1980)      625         1.0   \n",
       "3     Manon of the Spring (Manon des sources) (1986)      936         1.0   \n",
       "4                    Nikita (La Femme Nikita) (1990)      142         1.0   \n",
       "\n",
       "   Score of the NN  Contribution  \n",
       "0         1.399209      1.399209  \n",
       "1         1.399209      1.399209  \n",
       "2         1.399209      1.399209  \n",
       "3         1.399209      1.399209  \n",
       "4         1.399209      1.399209  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = defaultdict(list)\n",
    "score_arr = iknn_adjusted.ui_mat[UIDX].A.ravel()\n",
    "rated_items = np.nonzero(rating_mat[UIDX])[1]\n",
    "for rec in recommendations[:TOPK]:\n",
    "    sim_arr = iknn_adjusted.sim_mat[rec].A.ravel()\n",
    "    nearest_neighbor = rated_items[np.argsort(sim_arr[rated_items])[-1]]\n",
    "    sim = sim_arr[nearest_neighbor]\n",
    "    score = score_arr[nearest_neighbor]\n",
    "    df[\"Recommendation\"].append(item_df.loc[[int(item_idx2id[rec])]][\"Title\"].values[0])\n",
    "    df[\"Item NN\"].append(nearest_neighbor)\n",
    "    df[\"Similarity\"].append(sim)\n",
    "    df[\"Score of the NN\"].append(score)\n",
    "    df[\"Contribution\"].append((score * sim) / np.abs(sim))\n",
    "rec_df = pd.DataFrame.from_dict(df)\n",
    "rec_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to interpret the recommendation is to see how many neighboring items to the recommended item have been previously consumed by the user.  If there are many, then indeed this user may have a preference for similar movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j7/krgprqps37x2qnm719kc393r0000gn/T/ipykernel_2002/3991094398.py:11: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=\"Recommendation\", y=\"Number of rated NN\", data=rec_df, palette=\"ch:.25\", ax=ax);\n",
      "/var/folders/j7/krgprqps37x2qnm719kc393r0000gn/T/ipykernel_2002/3991094398.py:12: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(textwrap.fill(x.get_text(), 25) for x in ax.get_xticklabels());\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "rated_items = np.nonzero(rating_mat[UIDX])[1]\n",
    "n_nearest_neighbors = []\n",
    "for rec in recommendations[:TOPK]:\n",
    "    nearest_neighbors = np.argsort(iknn_adjusted.sim_mat[rec].A.ravel())[-K:]\n",
    "    n_nearest_neighbors.append(len(np.intersect1d(nearest_neighbors, rated_items)))\n",
    "rec_df[\"Number of rated NN\"] = n_nearest_neighbors\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "sns.barplot(\n",
    "    x=\"Recommendation\", y=\"Number of rated NN\", data=rec_df, palette=\"ch:.25\", ax=ax\n",
    ")\n",
    "ax.set_xticklabels(textwrap.fill(x.get_text(), 25) for x in ax.get_xticklabels());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the top recommendation is *Haunted World of Edward D. Wood Jr., The (1995)*, and 9 movies out of its 50 nearest-neighbors have been rated (probably watched) by the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1.   Aggarwal, C. C. (2016). Recommender systems (Vol. 1). Cham: Springer International Publishing.\n",
    "2.   Breese, J. S., Heckerman, D., & Kadie, C. (2013). Empirical analysis of predictive algorithms for collaborative filtering. arXiv preprint arXiv:1301.7363.\n",
    "3.   Sarwar, B., Karypis, G., Konstan, J., & Riedl, J. (2001, April). Item-based collaborative filtering recommendation algorithms. In Proceedings of the 10th international conference on World Wide Web (pp. 285-295)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envml3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
